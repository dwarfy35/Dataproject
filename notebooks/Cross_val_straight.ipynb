{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.decomposition import PCA \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, DetCurveDisplay, roc_auc_score\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_mers = [\"2\",\"2\",\"4\",\"4\",\"6\",\"6\"]\n",
    "checks = [True,False,True,False,True,False]\n",
    "colors = [\"b\",\"g\",\"r\",\"c\",\"m\",\"y\"]\n",
    "model_probs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=0.08697490026177834, max_iter=1000,\n",
      "                                    penalty='l1', solver='liblinear'))])\n",
      "Best parameter (C): {'logisticregression__C': 0.08697490026177834}\n",
      "Train accuracy: 0.6125\n",
      "Test accuracy: 0.6\n",
      "Best model: Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=9.111627561154895, max_iter=1000,\n",
      "                                    penalty='l1', solver='liblinear'))])\n",
      "Best parameter (C): {'logisticregression__C': 9.111627561154895}\n",
      "Train accuracy: 0.6166666666666667\n",
      "Test accuracy: 0.6041666666666666\n",
      "Best model: Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=0.049770235643321115, max_iter=1000,\n",
      "                                    penalty='l1', solver='liblinear'))])\n",
      "Best parameter (C): {'logisticregression__C': 0.049770235643321115}\n",
      "Train accuracy: 0.6604166666666667\n",
      "Test accuracy: 0.5958333333333333\n",
      "Best model: Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=0.049770235643321115, max_iter=1000,\n",
      "                                    penalty='l1', solver='liblinear'))])\n",
      "Best parameter (C): {'logisticregression__C': 0.049770235643321115}\n",
      "Train accuracy: 0.6604166666666667\n",
      "Test accuracy: 0.5458333333333333\n",
      "Best model: Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=0.11497569953977368, max_iter=1000,\n",
      "                                    penalty='l1', solver='liblinear'))])\n",
      "Best parameter (C): {'logisticregression__C': 0.11497569953977368}\n",
      "Train accuracy: 0.9604166666666667\n",
      "Test accuracy: 0.47291666666666665\n",
      "Best model: Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=0.06579332246575682, max_iter=1000,\n",
      "                                    penalty='l1', solver='liblinear'))])\n",
      "Best parameter (C): {'logisticregression__C': 0.06579332246575682}\n",
      "Train accuracy: 0.8375\n",
      "Test accuracy: 0.4708333333333333\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "model_probs = []\n",
    "for i in range(len(k_mers)):\n",
    "\n",
    "    #os.chdir(os.pardir)\n",
    "    Meth = pd.read_csv(\"processed_data\\combined_data\\with_background\\combined_\" + k_mers[i] + \"mers_meth_with_background.tsv\", sep=\"\\t\")\n",
    "    Unmeth = pd.read_csv(\"processed_data\\combined_data\\with_background\\combined_\" + k_mers[i] + \"mers_unmeth_with_background.tsv\", sep=\"\\t\")\n",
    "    Meth = Meth.drop(306)\n",
    "    Unmeth = Unmeth.drop(306)\n",
    "    Combined = [Meth,Unmeth]\n",
    "    Healthy_Meth = Meth.loc[Meth[\"cancer\"]==\"Healthy\"]\n",
    "    Healthy_Unmeth = Unmeth.loc[Unmeth[\"cancer\"]==\"Healthy\"]\n",
    "    Cancer_Meth = Meth.loc[Meth[\"cancer\"]!=\"Healthy\"]\n",
    "    Cancer_Unmeth = Unmeth.loc[Unmeth[\"cancer\"]==\"Healthy\"]\n",
    "    Data0 = Healthy_Meth\n",
    "    Data1 = Healthy_Unmeth\n",
    "    Combined = [Healthy_Meth,Healthy_Unmeth,Cancer_Meth,Cancer_Unmeth]\n",
    "    X = pd.concat(Combined)\n",
    "    X = X.iloc [:, :-1]\n",
    "    dim_reduction = PCA()\n",
    "    y = [0] * (Healthy_Meth.shape[0]+Healthy_Unmeth.shape[0]) + [1] * (Cancer_Meth.shape[0] + Cancer_Unmeth.shape[0])\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "    X_train = dim_reduction.fit_transform(X_train)\n",
    "    X_test = dim_reduction.transform(X_test)\n",
    "\n",
    "    # Create a pipeline with standardization and logistic regression with L1 regularization\n",
    "    pipe = make_pipeline(StandardScaler(),LogisticRegression(penalty='l1', solver='liblinear',max_iter=1000))\n",
    "    # Define hyperparameters grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'logisticregression__C': np.logspace(-3, 1, 100)  # Values for regularization parameter C\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV object\n",
    "    grid_search = GridSearchCV(pipe, param_grid, cv=10, n_jobs=-1)\n",
    "    # Fit the model using GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "    # Get the best model from GridSearchCV\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the best model\n",
    "    train_accuracy = best_model.score(X_train, y_train)\n",
    "    test_accuracy = best_model.score(X_test, y_test)\n",
    "    num_selected_variables = np.sum(best_model.named_steps['logisticregression'].coef_ != 0)\n",
    "\n",
    "    results.append([test_accuracy, grid_search.best_params_[\"logisticregression__C\"], num_selected_variables,[k_mers[i],checks[i]]])\n",
    "\n",
    "\n",
    "    plt.scatter(grid_search.cv_results_['param_logisticregression__C'], grid_search.cv_results_['mean_test_score'], color = colors[i])\n",
    "    plt.plot(grid_search.cv_results_['param_logisticregression__C'], grid_search.cv_results_['mean_test_score'], color = colors [i])\n",
    "    plt.xlabel(\"C\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.savefig(\"Cross_Val \" + k_mers[i] + \"-mer, PCA = \" + str(checks[i]))\n",
    "    plt.close()\n",
    "    \n",
    "   \n",
    "    dump(best_model,\"Straight_Cross_Val_\" + k_mers[i] + \"_mer__PCA_=_\" + str(checks[i]) + \".joblib\")\n",
    "\n",
    "\n",
    "    print(\"Best model:\", best_model)\n",
    "    print(\"Best parameter (C):\", grid_search.best_params_)\n",
    "    print(\"Train accuracy:\", train_accuracy)\n",
    "    print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k-mer</th>\n",
       "      <th>PCA</th>\n",
       "      <th>C</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Number of variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.086975</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>9.111628</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>0.049770</td>\n",
       "      <td>0.595833</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.049770</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0.114976</td>\n",
       "      <td>0.472917</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.065793</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  k-mer    PCA         C  Accuracy  Number of variables\n",
       "0     2   True  0.086975  0.600000                    6\n",
       "1     2  False  9.111628  0.604167                   16\n",
       "2     4   True  0.049770  0.595833                   12\n",
       "3     4  False  0.049770  0.545833                   15\n",
       "4     6   True  0.114976  0.472917                  174\n",
       "5     6  False  0.065793  0.470833                   74"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = []\n",
    "N_var = []\n",
    "Acc = []\n",
    "k_mer = []\n",
    "princ = []\n",
    "for i in range(len(results)):\n",
    "    C.append(results[i][1])\n",
    "    Acc.append(results[i][0])\n",
    "    N_var.append(results[i][2])\n",
    "    k_mer.append(results[i][3][0])\n",
    "    princ.append(results[i][3][1])\n",
    "Extra = pd.DataFrame({'k-mer':k_mer, 'PCA': princ, 'C': C, 'Accuracy': Acc, 'Number of variables': N_var})\n",
    "Extra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
